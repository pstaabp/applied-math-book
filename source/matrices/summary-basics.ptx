<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sect-linear-algebra-summary" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Summary of the basics of linear algebra</title>

  <p>We finish this chapter with a summarizing theorem about linear algebra.
    This covers how much of all of the above concepts are related. </p>


  <theorem xml:id="thm-nonsing-matrices">
    <statement>
      <p> Let <m>A</m> be an <m>n</m> by <m>n</m> matrix of real numbers. The following statements
        are equivalent: </p>

      <p>
        <ol>
          <li>
            <p>
              <m>|A| \neq 0</m>
            </p>
          </li>
          <li>
            <p> The inverse matrix, <m>A^{-1}</m> exists.</p>
          </li>
          <li>
            <p> For every vector <m>\vec{b}</m>, the equation <m>A \vec{x}=\vec{b}</m> has a unique
              solution <m>\vec{x} = A^{-1} \vec{b}</m>.</p>
          </li>
          <li>
            <p> The matrix equation <m>A \vec{x} = \vec{0}</m> has the unique solution <m>\vec{x} =
              \vec{0}</m>.</p>
          </li>
          <li>
            <p> The columns of <m>A</m> are linearly independent.</p>
          </li>
          <li>
            <p> The rows of <m>A</m> are linearly independent.</p>
          </li>
          <li>
            <p> The rank of <m>A</m> is <m>n</m>.</p>
          </li>
          <li>
            <p> The column space of <m>A</m> is <m>\mathbb{R}^n</m></p>
          </li>
          <li>
            <p> The row space of <m>A</m> is <m>\mathbb{R}^n</m>.</p>
          </li>
          <li>
            <p> The null space of <m>A</m> is <m>\{\vec{0}\}</m> and the nullity is 0.</p>
          </li>
          <li>
            <p> The reduced row echelon form of <m>A</m> is <m>I</m>, the identity matrix.</p>
          </li>
        </ol>
      </p>
    </statement>
  </theorem>

  <example>
    <statement>
      <p> Examine <xref ref="thm-nonsing-matrices" /> using the matrix </p>
      <p>
        <me>
          A = \begin{bmatrix}
          1 \amp 0 \amp 3 \\
          0 \amp 2 \amp -1 \\
          0 \amp 3 \amp -1
          \end{bmatrix}
        </me>
      </p>
    </statement>

    <solution>
      <p> In this example, we will show all of the equivalent properties directly on the matrix <m>A</m>
        . </p>
      <p>
        <ol>
          <li>
            <p> First find the determinant. Using the Laplace expansion method and expanding down
              the first column</p>
            <p>
              <me>
                |A| = 1 \begin{vmatrix}
                2 \amp -1 \\ 3 \amp -1
                \end{vmatrix} = 1 (2(-1)-(-1)3) = 1
              </me>
            </p>
            <p>
              which is nonzero.</p>
          </li>

          <li>
            <p> Next, we'll find the inverse matrix: <md>
                <mrow>\qquad \amp \left[\begin{array}{rrr|rrr}
                  1 \amp 0 \amp 3 \amp 1 \amp 0 \amp 0\\
                  0 \amp 2 \amp -1 \amp 0 \amp 1 \amp0 \\
                  0 \amp 3 \amp -1 \amp 0 \amp 0 \amp 1
                  \end{array}\right]</mrow>
                <mrow>-3 R_2 +2 R_3 \rightarrow R_3 \qquad \amp
                  \left[\begin{array}{rrr|rrr}
                  1 \amp 0 \amp 3 \amp 1 \amp 0 \amp 0\\
                  0 \amp 2 \amp -1 \amp 0 \amp 1 \amp0 \\
                  0 \amp 0 \amp 1 \amp 0 \amp -3 \amp 2
                  \end{array}\right]</mrow>
                <mrow>\begin{array}{r}
                  R_3 + R_2 \rightarrow R_2, \\
                  -3R_3 + R_1 \rightarrow R_1
                  \end{array} \qquad \amp
                  \left[\begin{array}{rrr|rrr}
                  1 \amp 0 \amp 0 \amp 1 \amp 9 \amp -6\\
                  0 \amp 2 \amp 0 \amp 0 \amp -2 \amp2 \\
                  0 \amp 0 \amp 1 \amp 0 \amp -3 \amp 2
                  \end{array}\right]</mrow>
                <mrow>\frac{1}{2} R_2 \rightarrow R_2 \qquad \amp
                  \left[\begin{array}{rrr|rrr}
                  1 \amp 0 \amp 0 \amp 1 \amp 9 \amp -6\\
                  0 \amp 1 \amp 0 \amp 0 \amp -1 \amp 1 \\
                  0 \amp 0 \amp 1 \amp 0 \amp -3 \amp 2
                  \end{array}\right]</mrow>
              </md></p>
            <p> and this shows that the inverse
              matrix is</p>
            <p>
              <me>
                A^{-1} = \begin{bmatrix}
                1 \amp 9 \amp -6\\
                0 \amp -1 \amp 1 \\
                0 \amp -3 \amp 2
                \end{bmatrix}
              </me>
            </p>
          </li>

          <li>
            <p> Since the inverse matrix exists, then a unique solution to <m>A\vec{x}=\vec{b}</m>
              can be found by <m>\vec{x}=A^{-1}\vec{b}</m>.</p>
          </li>

          <li>
            <p> Again, since <m>A^{-1}</m> exists, then</p>
            <p>
              <me>
                \vec{x} = A^{-1}\vec{0} = \vec{0}
              </me>
            </p>
          </li>

          <li>
            <p> See #8 below.</p>
          </li>
          <li>
            <p> See #9 below.</p>
          </li>
          <li>
            <p> See #8 and #9 below.</p>
          </li>

          <li>
            <p> The column space is found by row reducing <m>A^{\intercal}</m>.
            </p>
            <p> <md>
                <mrow>A^{\intercal} = \amp\begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 2 \amp 3 \\
                  3 \amp -1 \amp -1
                  \end{bmatrix} </mrow>
                <mrow>-3 R_1 + R_3 \rightarrow R_3 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 2 \amp 3\\
                  0 \amp -1 \amp -1
                  \end{bmatrix} </mrow>
                <mrow>R_2 + 2 R_3 \rightarrow R_3 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 2 \amp 3\\
                  0 \amp 0 \amp 1
                  \end{bmatrix} </mrow>
              </md></p>
            <p>
              which is now in echelon form and since all nonzero row in a echelon form matrix are
              linearly independent, this shows #5.
            </p>
            <p>
              Continuing to put this is reduced row echelon form:</p>
            <p>
              <md>
                <mrow>-3R_3 + R_2 \rightarrow R_2 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 2 \amp 0\\
                  0 \amp 0 \amp 1
                  \end{bmatrix} </mrow>
                <mrow>\frac{1}{2} R_2 \rightarrow R_2 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 1 \amp 0\\
                  0 \amp 0 \amp 1
                  \end{bmatrix}</mrow>
              </md>
            </p>
            <p> and this shows that the column space of <m>A</m> is</p>
            <p>
              <me>
                \text{span}\left(\left\{ \begin{bmatrix}
                1 \\ 0 \\ 0
                \end{bmatrix}, \begin{bmatrix}
                0 \\ 1\\0
                \end{bmatrix}, \begin{bmatrix}
                0 \\ 0 \\ 1
                \end{bmatrix} \right\} \right)
              </me>
            </p>
            <p> which is all of <m>\mathbb{R}^3</m>. This also shows that the rank of <m>A</m> is 3.</p>
          </li>

          <li>
            <p> In a similar manner to #8, we put <m>A</m> in reduced row echelon form: </p>
            <p>
              <md>
                <mrow>\qquad \amp \begin{bmatrix}
                  1 \amp 0 \amp 3 \\
                  0 \amp 2 \amp -1 \\
                  0 \amp 3 \amp -1
                  \end{bmatrix} </mrow>
                <mrow>-3 R_2 +2 R_3 \rightarrow R_3 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 3 \\
                  0 \amp 2 \amp -1\\
                  0 \amp 0 \amp 1
                  \end{bmatrix} </mrow>
                <mrow>\begin{array}{r}
                  R_3 + R_2 \rightarrow R_2, \\
                  -3R_3 + R_1 \rightarrow R_1
                  \end{array} \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 2 \amp 0 \\
                  0 \amp 0 \amp 1
                  \end{bmatrix} </mrow>
                <mrow>\frac{1}{2} R_2 \rightarrow R_2 \qquad \amp
                  \begin{bmatrix}
                  1 \amp 0 \amp 0 \\
                  0 \amp 1 \amp 0 \\
                  0 \amp 0 \amp 1
                  \end{bmatrix}</mrow>
              </md>
            </p>
            <p>
              and thus the row space is
            </p>
            <p>
              <me>
                \text{span}(\{ \begin{bmatrix}
                1 \amp 0 \amp 0
                \end{bmatrix},\begin{bmatrix}
                0 \amp 1 \amp 0
                \end{bmatrix},\begin{bmatrix}
                0 \amp 0 \amp 1
                \end{bmatrix} \})
              </me>
            </p>
            <p> and this is <m>\mathbb{R}^3</m>. In addition, this shows that the rank of <m>A</m>
              is 3.</p>
          </li>


          <li>
            <p> The null space is the set of all <m>\vec{x}</m> such that <m>A\vec{x}=\vec{0}</m>,
              but from #4, we showed that the only solution to this is <m>\vec{x}=\vec{0}</m>. The
              nullity is the number of linearly independent vectors in this set which is 0, by
              definition. </p>
          </li>

          <li>
            <p> From #9, we showed that the reduced row echelon form of <m>A</m> is <m>I</m>.</p>
          </li>
        </ol>
      </p>
    </solution>

  </example>


  <theorem xml:id="thm-sing-matrices">
    <statement>
      <p> Let <m>A</m> be an <m>n \times n</m> real matrix. The following statements are equivalent </p>
      <p>
        <ol>
          <li>
            <p>
              <m>|A|=0</m>
            </p>
          </li>
          <li>
            <p> The matrix equation <m>A \vec{x} = \vec{b}</m> has no solution or an infinite number
              of solutions. </p>
          </li>
          <li>
            <p> The matrix equation <m>A \vec{x} = \vec{0}</m> has a nontrivial solution.</p>
          </li>
          <li>
            <p> The rank of <m>A</m> is less than <m>n</m>.</p>
          </li>
        </ol>
      </p>
    </statement>
  </theorem>


  <p> This theorem will be extremely helpful in finding a certain type of
    scalar and vector called an eigenvalue and eigenvector.
    The following example shows its usefulness. </p>

  <example>
    <statement>
      <p>
        Let</p>
      <p>
        <me>
          A  = \begin{bmatrix}
          1 \amp 0 \amp 2 \\
          0 \amp -2 \amp 1 \\
          2 \amp -2 \amp 5
          \end{bmatrix}
        </me>
      </p>
      <p> Show that <m>A\vec{x} = \vec{0}</m> has a nontrivial solution first by using <xref
          ref="thm-sing-matrices" /> then by directly finding solutions.</p>
    </statement>

    <solution>
      <p>
        First, find the determinant by expansion:
</p>
      <p>
        <md>
          <mrow>|A| \amp = 1 \begin{vmatrix}
            -2 \amp 1 \\ -2 \amp 5
            \end{vmatrix} + 2 \begin{vmatrix}
            0 \amp -2 \\ 2 \amp -2
            \end{vmatrix} </mrow>
          <mrow>\amp = (-10-(-2)) + 2 (0-(-4)) = -8 + 8 = 0 </mrow>
        </md>
      </p>
      <p> and therefore by Theorem <xref ref="thm-sing-matrices" />, there is a nontrivial solution
        to <m>A \vec{x} = \vec{0}</m>
      </p>

      <p> Next, we'll solve the matrix equation by Gauss' method.
</p>
      <p>
        <md>
          <mrow>\amp \qquad \left[\begin{array}{rrr|r}
            1 \amp 0 \amp 2 \amp 0 \\
            0 \amp -2 \amp 1 \amp 0 \\
            2 \amp -2 \amp 5 \amp 0
            \end{array}\right] </mrow>
          <mrow>-2 R_1 + R_3 \rightarrow R_3
            \amp \qquad \left[\begin{array}{rrr|r}
            1 \amp 0 \amp 2 \amp 0 \\
            0 \amp -2 \amp 1 \amp 0 \\
            0 \amp -2 \amp 1 \amp 0
            \end{array}\right] </mrow>
          <mrow>-R_2 + R_3 \rightarrow R_3
            \amp \qquad \left[\begin{array}{rrr|r}
            1 \amp 0 \amp 2 \amp 0 \\
            0 \amp -2 \amp 1 \amp 0 \\
            0 \amp 0 \amp 0 \amp 0
            \end{array}\right] </mrow>
        </md>
      </p>
      <p>
        The resulting equations are
</p>
      <p>
        <md>
          <mrow>x_1 + 2x_3 \amp = 0 </mrow>
          <mrow>-2x_2 + x_3 \amp = 0</mrow>
        </md>
      </p>
      <p>
        or</p>
      <p>
        <md>
          <mrow>x_1 \amp = -2x_3 </mrow>
          <mrow>x_2 \amp = \frac{1}{2} x_3</mrow>
        </md>
      </p>
      <p>
        and the solution set is
      </p>
      <p>
        <me>
          \left\{ \begin{bmatrix}
          -2 \\ 1/2 \\ 1
          \end{bmatrix} x_3 \; | \; x_3 \in \mathbb{R} \right\}
        </me>
      </p>
      <p> This shows directly that the matrix equation <m>A\vec{x}=\vec{0}</m> does not have a
        trivial solution. </p>
    </solution>
  </example>

<p> Also notice that the last matrix of Gauss' method showed that the
  rank was 2 (since there were only 2 nonzero rows).
  This was another statement in the theorem. </p>


</section>